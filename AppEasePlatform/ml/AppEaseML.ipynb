{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AppEase Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you use automated machine learning in Azure Machine Learning service to create a classification model to predict labels. This process accepts training data and configuration settings, and automatically iterates through combinations of different feature normalization/standardization methods, models, and hyperparameter settings to arrive at the best model.\n",
    "\n",
    "To run this notebook, you only need an Azure subscription. Additionally, the data and labels JSON files need to be in the local directory. These two files should be merge-able on the index, and they should contain at least 63 records of data for training (this is the minimum assuming a 0.8/0.2 train/test split).\n",
    "\n",
    "We found it easier to run this notebook in an Azure Data Science Virtual Machine using a Python 3 kernel to ensure that all the necessary packages were available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "gather": {
     "logged": 1621310166522
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import azureml.core\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "import logging\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.widgets import RunDetails\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1621306775457
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# required info\n",
    "subscription = '<your-azure-subscription-id>'\n",
    "\n",
    "# you choose these\n",
    "workspace_resource_group = None # replace this if you'd like to use a pre-built resource group\n",
    "workspace_loc = 'eastus' # feel free to change this\n",
    "workspace_name = 'appeasewML'\n",
    "compute_cluster_name = 'appeasecompute'\n",
    "\n",
    "# name of files in local directory with data and labels (to be merged on indexes)\n",
    "# NOTE: data_file must contain at least 63 records of data for training (with 0.8/0.2 train/test split)\n",
    "data_file_name = 'simulated_health_data.json'\n",
    "labels_file_name = 'random_labels.json'\n",
    "label_column_name = 'Label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1621306837527
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# create an Azure workspace\n",
    "if workspace_resource_group == None:\n",
    "    create_RG = True\n",
    "else:\n",
    "    create_RG = False\n",
    "\n",
    "try:\n",
    "    ws = Workspace.get(name=workspace_name, subscription_id= subscription, resource_group=workspace_resource_group)\n",
    "except:\n",
    "    ws = Workspace.create(name= workspace_name, subscription_id=subscription,resource_group=workspace_resource_group, create_resource_group=create_RG,location=workspace_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1621306885120
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# create an Azure compute cluster\n",
    "try: # Verify that cluster does not exist already\n",
    "    cpu_cluster = ComputeTarget(workspace=ws, name=compute_cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',max_nodes=4)\n",
    "    cpu_cluster = ComputeTarget.create(ws, compute_cluster_name, compute_config)\n",
    "\n",
    "cpu_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1621306885210
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "data = pd.read_json(data_file_name)\n",
    "\n",
    "# convert data types to int\n",
    "data['bloodType'].replace(['A-','A+','B-','B+','AB-','AB+','O-','O+'], [0,1,2,3,4,5,6,7], inplace=True)\n",
    "data['sex'].replace(['Male','Female'],[0,1],inplace=True)\n",
    "data['name'] = data['name'].map(lambda x: int(x[4:]))\n",
    "data['TimeStamp'] = data['TimeStamp'].astype(int)\n",
    "\n",
    "labels = pd.read_json(labels_file_name, typ='series')\n",
    "final_df = data.merge(labels.rename('Label'), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1621306885289
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "x_train, x_test = train_test_split(final_df, test_size=0.2, random_state=223)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1621306885377
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# define settings for the experiment run (see parameters at https://docs.microsoft.com/azure/machine-learning/service/how-to-configure-auto-train)\n",
    "automl_settings = {\n",
    "    \"n_cross_validations\": 3,\n",
    "    \"primary_metric\": \"accuracy\",\n",
    "    \"experiment_timeout_hours\": 0.25,  # This is a time limit for testing purposes, remove it for real use cases, this will drastically limit ability to find the best model possible\n",
    "    \"verbosity\": logging.INFO,\n",
    "    \"enable_stack_ensemble\": False,\n",
    "}\n",
    "\n",
    "automl_config = AutoMLConfig(\n",
    "    task=\"classification\",\n",
    "    debug_log=\"automl_errors.log\",\n",
    "    training_data=x_train,\n",
    "    label_column_name=label_column_name,\n",
    "    **automl_settings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1621305901405
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# create and run the Experiment\n",
    "experiment = Experiment(ws, \"AppEaseML\")\n",
    "local_run = experiment.submit(automl_config, show_output=True) # this can take about 20 minutes with the default settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1621309357479
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# explore the results and retrieve the best model\n",
    "best_run, best_model = local_run.get_output()\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1621305902597
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# calculate the root mean squared error, mean absolute percent error, and accuracy of the best model\n",
    "y_test = x_test.pop(\"Label\")\n",
    "y_predict = best_model.predict(x_test)\n",
    "\n",
    "y_actual = y_test.values.flatten().tolist()\n",
    "rmse = sqrt(mean_squared_error(y_actual, y_predict))\n",
    "print(\"Model RMSE:\")\n",
    "print(rmse)\n",
    "print()\n",
    "\n",
    "sum_actuals = sum_errors = 0\n",
    "\n",
    "for actual_val, predict_val in zip(y_actual, y_predict):\n",
    "    abs_error = actual_val - predict_val\n",
    "    if abs_error < 0:\n",
    "        abs_error = abs_error * -1\n",
    "\n",
    "    sum_errors = sum_errors + abs_error\n",
    "    sum_actuals = sum_actuals + actual_val\n",
    "\n",
    "mean_abs_percent_error = sum_errors / sum_actuals\n",
    "print(\"Model MAPE:\")\n",
    "print(mean_abs_percent_error)\n",
    "print()\n",
    "print(\"Model Accuracy:\")\n",
    "print(1 - mean_abs_percent_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1621310159304
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# save the best model\n",
    "pkl_filename = \"best_model.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(best_model, file)\n",
    "\n",
    "# save training data and labels\n",
    "data.to_csv('train_data.csv', index = False, header= True)\n",
    "labels.to_csv('train_labels.csv', index= False, header = 'Label')"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "jeffshep"
   }
  ],
  "categories": [
   "tutorials"
  ],
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "msauthor": "trbye",
  "network_required": false,
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
