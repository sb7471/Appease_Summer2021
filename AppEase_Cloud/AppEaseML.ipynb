{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AppEase Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you use automated machine learning in Azure Machine Learning service to create a classification model to predict labels. This process accepts training data and configuration settings, and automatically iterates through combinations of different feature normalization/standardization methods, models, and hyperparameter settings to arrive at the best model.\n",
    "\n",
    "To run this notebook, you only need an Azure subscription. Additionally, the data and labels JSON files need to be in the local directory. These two files should be merge-able on the index, and they should contain at least 63 records of data for training (this is the minimum assuming a 0.8/0.2 train/test split).\n",
    "\n",
    "We found it easier to run this notebook in an Azure Data Science Virtual Machine using a Python 3 kernel to ensure that all the necessary packages were available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1621310166522
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import azureml.core\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "import logging\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.widgets import RunDetails\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1621306775457
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# required info\n",
    "subscription = '574c17c0-996b-490d-a26a-3faa4e105b6d'\n",
    "\n",
    "# you choose these\n",
    "workspace_resource_group = 'AppEase' # replace this if you'd like to use a pre-built resource group\n",
    "workspace_loc = 'eastus' # feel free to change this\n",
    "workspace_name = 'appeasewML'\n",
    "compute_cluster_name = 'appeasecompute'\n",
    "\n",
    "# name of files in local directory with data and labels (to be merged on indexes)\n",
    "# NOTE: data_file must contain at least 63 records of data for training (with 0.8/0.2 train/test split)\n",
    "data_file_name = 'simulated_health_data.json'\n",
    "labels_file_name = 'random_labels.json'\n",
    "label_column_name = 'Label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1621306837527
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing interactive authentication. Please follow the instructions on the terminal.\n",
      "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code EFA3D85L3 to authenticate.\n",
      "You have logged in. Now let us find all the subscriptions to which you have access...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "get_workspace error using subscription_id=574c17c0-996b-490d-a26a-3faa4e105b6d, resource_group_name=AppEase, workspace_name=appeasewML\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive authentication successfully completed.\n",
      "Deploying StorageAccount with name appeasewstorageb908b43bf.\n",
      "Deploying AppInsights with name appeasewinsights228e3399.\n",
      "Deployed AppInsights with name appeasewinsights228e3399. Took 7.61 seconds.\n",
      "Deploying KeyVault with name appeasewkeyvault4a41c505.\n",
      "Deployed KeyVault with name appeasewkeyvault4a41c505. Took 21.87 seconds.\n",
      "Deploying Workspace with name appeasewML.\n",
      "Deployed StorageAccount with name appeasewstorageb908b43bf. Took 27.63 seconds.\n",
      "Deployed Workspace with name appeasewML. Took 62.68 seconds.\n"
     ]
    }
   ],
   "source": [
    "# create an Azure workspace\n",
    "if workspace_resource_group == None:\n",
    "    create_RG = True\n",
    "else:\n",
    "    create_RG = False\n",
    "\n",
    "try:\n",
    "    ws = Workspace.get(name=workspace_name, subscription_id= subscription, resource_group=workspace_resource_group)\n",
    "except:\n",
    "    ws = Workspace.create(name= workspace_name, subscription_id=subscription,resource_group=workspace_resource_group, create_resource_group=create_RG,location=workspace_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "gather": {
     "logged": 1621306885120
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InProgress.........\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "# create an Azure compute cluster\n",
    "try: # Verify that cluster does not exist already\n",
    "    cpu_cluster = ComputeTarget(workspace=ws, name=compute_cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',max_nodes=4)\n",
    "    cpu_cluster = ComputeTarget.create(ws, compute_cluster_name, compute_config)\n",
    "\n",
    "cpu_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "gather": {
     "logged": 1621306885210
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "data = pd.read_json(data_file_name)\n",
    "\n",
    "# convert data types to int\n",
    "data['bloodType'].replace(['A-','A+','B-','B+','AB-','AB+','O-','O+'], [0,1,2,3,4,5,6,7], inplace=True)\n",
    "data['sex'].replace(['Male','Female'],[0,1],inplace=True)\n",
    "data['name'] = data['name'].map(lambda x: int(x[4:]))\n",
    "data['TimeStamp'] = data['TimeStamp'].astype(int)\n",
    "\n",
    "labels = pd.read_json(labels_file_name, typ='series')\n",
    "final_df = data.merge(labels.rename('Label'), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "gather": {
     "logged": 1621306885289
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "x_train, x_test = train_test_split(final_df, test_size=0.2, random_state=223)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "gather": {
     "logged": 1621306885377
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define settings for the experiment run (see parameters at https://docs.microsoft.com/azure/machine-learning/service/how-to-configure-auto-train)\n",
    "automl_settings = {\n",
    "    \"n_cross_validations\": 3,\n",
    "    \"primary_metric\": \"accuracy\",\n",
    "    \"experiment_timeout_hours\": 0.25,  # This is a time limit for testing purposes, remove it for real use cases, this will drastically limit ability to find the best model possible\n",
    "    \"verbosity\": logging.INFO,\n",
    "    \"enable_stack_ensemble\": False,\n",
    "}\n",
    "\n",
    "automl_config = AutoMLConfig(\n",
    "    task=\"classification\",\n",
    "    debug_log=\"automl_errors.log\",\n",
    "    training_data=x_train,\n",
    "    label_column_name=label_column_name,\n",
    "    **automl_settings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "gather": {
     "logged": 1621305901405
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No run_configuration provided, running on local with default configuration\n",
      "Running in the active local environment.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>AppEaseML</td><td>AutoML_2a41b9e7-10e7-4834-a59e-0f003ae86b0d</td><td>automl</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/AutoML_2a41b9e7-10e7-4834-a59e-0f003ae86b0d?wsid=/subscriptions/574c17c0-996b-490d-a26a-3faa4e105b6d/resourcegroups/AppEase/workspaces/appeasewML&amp;tid=7b331012-87a1-4a16-8b0f-a4605b1f3d7f\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current status: DatasetEvaluation. Gathering dataset statistics.\n",
      "Current status: FeaturesGeneration. Generating features for the dataset.\n",
      "Current status: DatasetFeaturization. Beginning to fit featurizers and featurize the dataset.\n",
      "Current status: DatasetFeaturizationCompleted. Completed fit featurizers and featurizing the dataset.\n",
      "Current status: DatasetCrossValidationSplit. Generating individually featurized CV splits.\n",
      "\n",
      "****************************************************************************************************\n",
      "DATA GUARDRAILS: \n",
      "\n",
      "TYPE:         Class balancing detection\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  Your inputs were analyzed, and all classes are balanced in your training data.\n",
      "              Learn more about imbalanced data: https://aka.ms/AutomatedMLImbalancedData\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "TYPE:         Missing feature values imputation\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  No feature missing values were detected in the training data.\n",
      "              Learn more about missing value imputation: https://aka.ms/AutomatedMLFeaturization\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "TYPE:         High cardinality feature detection\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  Your inputs were analyzed, and no high cardinality features were detected.\n",
      "              Learn more about high cardinality feature handling: https://aka.ms/AutomatedMLFeaturization\n",
      "\n",
      "****************************************************************************************************\n",
      "Current status: ModelSelection. Beginning model selection.\n",
      "\n",
      "****************************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "****************************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
      "         0   MaxAbsScaler LightGBM                          0:00:20       0.6928    0.6928\n",
      "         1   MaxAbsScaler XGBoostClassifier                 0:00:19       0.5566    0.6928\n",
      "         2   MaxAbsScaler ExtremeRandomTrees                0:00:20       0.5752    0.6928\n",
      "         3   SparseNormalizer XGBoostClassifier             0:00:18       0.6732    0.6928\n",
      "         4   StandardScalerWrapper KNN                      0:00:19       0.5763    0.6928\n",
      "         5   MaxAbsScaler LightGBM                          0:00:19       0.6928    0.6928\n",
      "         6   RobustScaler LogisticRegression                0:00:18       0.4597    0.6928\n",
      "         7   MaxAbsScaler LightGBM                          0:00:19       0.6928    0.6928\n",
      "         8   StandardScalerWrapper KNN                      0:00:19       0.5959    0.6928\n",
      "         9   StandardScalerWrapper SVM                      0:00:19       0.6187    0.6928\n",
      "        10   StandardScalerWrapper XGBoostClassifier        0:00:19       0.5359    0.6928\n",
      "        11   MinMaxScaler RandomForest                      0:00:21       0.5556    0.6928\n",
      "        12   StandardScalerWrapper LogisticRegression       0:00:20       0.3845    0.6928\n",
      "        13   StandardScalerWrapper KNN                      0:00:20       0.6928    0.6928\n",
      "        14   RobustScaler KNN                               0:00:19       0.5392    0.6928\n",
      "        15   MinMaxScaler KNN                               0:00:21       0.6144    0.6928\n",
      "        16   SparseNormalizer KNN                           0:00:19       0.7113    0.7113\n",
      "        17   MaxAbsScaler LogisticRegression                0:00:18       0.5370    0.7113\n",
      "        18   StandardScalerWrapper XGBoostClassifier        0:00:20       0.6536    0.7113\n",
      "        19   StandardScalerWrapper XGBoostClassifier        0:00:30       0.6351    0.7113\n",
      "        20   MaxAbsScaler LogisticRegression                0:00:20       0.4608    0.7113\n",
      "        21   StandardScalerWrapper XGBoostClassifier        0:00:19       0.6928    0.7113\n",
      "        22   StandardScalerWrapper LightGBM                 0:00:18       0.6536    0.7113\n",
      "        23   StandardScalerWrapper RandomForest             0:00:20       0.6340    0.7113\n",
      "        24   RobustScaler LightGBM                          0:00:19       0.6732    0.7113\n",
      "        25                                                  0:00:06          nan    0.7113\n",
      "ERROR: PipelineRunException:\n",
      "\tMessage: PipelineRunException: Pipeline execution failed with ValueError: Expected n_neighbors <= n_samples,  but n_samples = 34, n_neighbors = 51\n",
      "\tInnerException: ValueError: Expected n_neighbors <= n_samples,  but n_samples = 34, n_neighbors = 51\n",
      "\tErrorResponse \n",
      "{\n",
      "    \"error\": {\n",
      "        \"code\": \"SystemError\",\n",
      "        \"message\": \"Encountered an internal AutoML error. Error Message/Code: PipelineRunException. Additional Info: PipelineRunException:\\n\\tMessage: PipelineRunException: Pipeline execution failed with ValueError: Expected n_neighbors <= n_samples,  but n_samples = 34, n_neighbors = 51\\n\\tInnerException: None\\n\\tErrorResponse \\n{\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"PipelineRunException: Pipeline execution failed with ValueError: Expected n_neighbors <= n_samples,  but n_samples = 34, n_neighbors = 51\\\",\\n        \\\"target\\\": \\\"spawn_client\\\",\\n        \\\"reference_code\\\": \\\"spawn_client\\\"\\n    }\\n}\",\n",
      "        \"details_uri\": \"https://aka.ms/automltroubleshoot\",\n",
      "        \"target\": \"spawn_client\",\n",
      "        \"inner_error\": {\n",
      "            \"code\": \"ClientError\",\n",
      "            \"inner_error\": {\n",
      "                \"code\": \"AutoMLInternal\"\n",
      "            }\n",
      "        },\n",
      "        \"reference_code\": \"spawn_client\"\n",
      "    }\n",
      "}\n",
      "        26   StandardScalerWrapper LightGBM                 0:00:19       0.5370    0.7113\n",
      "        27   StandardScalerWrapper GradientBoosting         0:00:20       0.6144    0.7113\n",
      "        28   SparseNormalizer XGBoostClassifier             0:00:20       0.6340    0.7113\n",
      "        29   SparseNormalizer LightGBM                      0:00:19       0.6906    0.7113\n",
      "        30   VotingEnsemble                                 0:00:18       0.7113    0.7113\n",
      "Stopping criteria reached at iteration 31. Ending experiment.\n",
      "****************************************************************************************************\n",
      "Current status: BestRunExplainModel. Best run model explanations started\n",
      "Current status: ModelExplanationDataSetSetup. Model explanations data setup completed\n",
      "Current status: PickSurrogateModel. Choosing LightGBM as the surrogate model for explanations\n",
      "Current status: EngineeredFeatureExplanations. Computation of engineered features started\n",
      "Current status: EngineeredFeatureExplanations. Computation of engineered features completed\n",
      "Current status: RawFeaturesExplanations. Computation of raw features started\n",
      "Current status: RawFeaturesExplanations. Computation of raw features completed\n",
      "Current status: BestRunExplainModel. Best run model explanations completed\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# create and run the Experiment\n",
    "experiment = Experiment(ws, \"AppEaseML\")\n",
    "local_run = experiment.submit(automl_config, show_output=True) \n",
    "# this can take about 20 minutes with the default settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "gather": {
     "logged": 1621309357479
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('datatransformer',\n",
       "                 DataTransformer(enable_dnn=False, enable_feature_sweeping=True, feature_sweeping_config={}, feature_sweeping_timeout=86400, featurization_config=None, force_text_dnn=False, is_cross_validation=True, is_onnx_compatible=False, observer=None, task='classification', working_dir='/home/appeaseuser/notebooks/AppEase_Cloud')),\n",
       "                ('SparseNormalizer', Normalizer(copy=True, norm='max')),\n",
       "                ('KNeighborsClassifier',\n",
       "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                      metric='manhattan', metric_params=None,\n",
       "                                      n_jobs=1, n_neighbors=10, p=2,\n",
       "                                      weights='distance'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explore the results and retrieve the best model\n",
    "best_run, best_model = local_run.get_output()\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "gather": {
     "logged": 1621305902597
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model RMSE:\n",
      "0.7844645405527362\n",
      "\n",
      "Model MAPE:\n",
      "1.1428571428571428\n",
      "\n",
      "Model Accuracy:\n",
      "-0.1428571428571428\n"
     ]
    }
   ],
   "source": [
    "# calculate the root mean squared error, mean absolute percent error, and accuracy of the best model\n",
    "y_test = x_test.pop(\"Label\")\n",
    "y_predict = best_model.predict(x_test)\n",
    "\n",
    "y_actual = y_test.values.flatten().tolist()\n",
    "rmse = sqrt(mean_squared_error(y_actual, y_predict))\n",
    "print(\"Model RMSE:\")\n",
    "print(rmse)\n",
    "print()\n",
    "\n",
    "sum_actuals = sum_errors = 0\n",
    "\n",
    "for actual_val, predict_val in zip(y_actual, y_predict):\n",
    "    abs_error = actual_val - predict_val\n",
    "    if abs_error < 0:\n",
    "        abs_error = abs_error * -1\n",
    "\n",
    "    sum_errors = sum_errors + abs_error\n",
    "    sum_actuals = sum_actuals + actual_val\n",
    "\n",
    "mean_abs_percent_error = sum_errors / sum_actuals\n",
    "print(\"Model MAPE:\")\n",
    "print(mean_abs_percent_error)\n",
    "print()\n",
    "print(\"Model Accuracy:\")\n",
    "print(1 - mean_abs_percent_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "gather": {
     "logged": 1621310159304
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save the best model\n",
    "pkl_filename = \"best_model.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(best_model, file)\n",
    "\n",
    "# save training data and labels\n",
    "data.to_csv('train_data.csv', index = False, header= True)\n",
    "labels.to_csv('train_labels.csv', index= False, header = 'Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "jeffshep"
   }
  ],
  "categories": [
   "tutorials"
  ],
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "azureml_py36_automl",
   "language": "python",
   "name": "conda-env-azureml_py36_automl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "msauthor": "trbye",
  "network_required": false,
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
